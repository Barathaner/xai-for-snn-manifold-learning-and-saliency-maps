# Liquid State Machine mit E-Prop in SNNTorch oder Online learning fÃ¼r Spiking Neural Networks (Reservoir Computing Architecture)
Das Verarbeiten zeitlich kodierter Informationen (z.â€¯B. gesprochene Sprache, sensorische Daten oder EreignisstrÃ¶me) stellt klassische neuronale Netzwerke vor Herausforderungen, insbesondere im Hinblick auf Energieeffizienz, Online-Lernen und zeitliche Dynamik.
Zwar liefern kÃ¼nstliche neuronale Netze (ANNs) bei statischen Aufgaben wie Bildklassifikation starke Ergebnisse, doch sie sind:

- schwer Ã¼ber Zeit zu trainieren (z.â€¯B. bei kontinuierlichen Signalen),
- nicht biologisch plausibel,
- energieintensiv.

Dieses Repository implementiert eine Liquid State Machine (LSM) â€“ ein rekurrentes Spiking Neural Network (SNN) mit fest verdrahtetem Reservoir â€“ und kombiniert sie mit dem E-Prop Algorithmus zur biologisch inspirierten Online-Gewichtsaktualisierung.

## Ziel:
Ein Framework fÃ¼r das Training eines spikenden Klassifikators auf dem Spiking Heidelberg Digits (SHD) Datensatz, das folgende Eigenschaften erfÃ¼llt:

- ğŸ§  Zeitliche Verarbeitung von Spikes Ã¼ber ein rekurrentes Reservoir

- ğŸ” E-Prop als lokale, onlinefÃ¤hige Lernregel ohne Backpropagation Through Time (BPTT)

- ğŸ§± Modularer Code, der leicht anpassbar und wiederverwendbar ist

- ğŸ”Œ Vorbereitung fÃ¼r spÃ¤tere Integration in Anwendungen oder auf neuromorpher Hardware
## Project Structure
```bash
lsm_eprop_shd/
â”œâ”€â”€ config/                     # Konfigurationsdateien
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ data/                       # Rohdaten und Preprocessing-Skripte
â”‚   â”œâ”€â”€ raw/                    # (Optional: Originale SHD-Daten)
â”‚   â””â”€â”€ processed/              # Preprocessed Data (npz, pt, ...)
â”‚   â””â”€â”€ dataloader.py
â”œâ”€â”€ models/                     # Model-Architekturen
â”‚   â”œâ”€â”€ lsm.py                  # Liquid State Machine Definition
â”‚   â”œâ”€â”€ eprop.py                # E-Prop Algorithmus / Lernregeln
â”‚   â””â”€â”€ neuron_models.py        # Custom Neurons, z. B. LIF, ALIF etc.
â”œâ”€â”€ training/                   # Trainings- und Evaluationslogik
â”‚   â”œâ”€â”€ trainer.py              # Trainingsloop
â”‚   â”œâ”€â”€ evaluator.py            # Auswertung (Accuracy, Spikes etc.)
â”‚   â””â”€â”€ callbacks.py            # Logging, EarlyStopping etc.
â”œâ”€â”€ utils/                      # Hilfsfunktionen
â”‚   â”œâ”€â”€ spike_tools.py          # Spike-Statistiken, Visualisierung
â”‚   â””â”€â”€ metrics.py              # Loss-Funktionen, Energie-Metriken
â”œâ”€â”€ experiments/                # Trainingsskripte (fÃ¼r verschiedene Runs)
â”‚   â””â”€â”€ run_shd_lsm.py          # Einstiegspunkt (Trainingskonfiguration)
â”œâ”€â”€ tests/                      # Unit Tests
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ notebooks/                  # FÃ¼r Exploration, Debugging, Visualisierung
â”‚   â””â”€â”€ data_exploration.ipynb
â”œâ”€â”€ README.md                   # Projektbeschreibung
â”œâ”€â”€ requirements.txt            # Python-AbhÃ¤ngigkeiten
â””â”€â”€ .gitignore

```
