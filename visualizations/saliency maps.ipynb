{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "# Lade ein vortrainiertes ResNet50-Modell und setze es in den Evaluationsmodus\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval()\n",
    "\n",
    "# Definiere die Transformationen: Bildgröße anpassen, in Tensor umwandeln und normalisieren\n",
    "# Diese Normalisierungswerte sind Standard für Modelle, die auf ImageNet trainiert wurden\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Lade das gleiche Beispielbild\n",
    "img_url = 'https://upload.wikimedia.org/wikipedia/commons/f/f9/Zoorashia_elephant.jpg'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(img_url, headers=headers)\n",
    "img_pil = Image.open(BytesIO(response.content)).convert('RGB') # Stelle sicher, dass es RGB ist\n",
    "\n",
    "# Wende die Transformationen an\n",
    "img_tensor = transform(img_pil).unsqueeze(0) # Füge eine Batch-Dimension hinzu\n",
    "\n",
    "# Zeige das Originalbild (vor der Normalisierung) an\n",
    "plt.imshow(img_pil)\n",
    "plt.title(\"Unser Testbild: Ein Elefant\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade die ImageNet-Klassennamen\n",
    "class_url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "\n",
    "# --- KORREKTUR ---\n",
    "# Verwende die .json()-Methode von requests, um die Antwort direkt zu dekodieren\n",
    "class_idx = requests.get(class_url).json() \n",
    "# --- KORREKTUR ENDE ---\n",
    "\n",
    "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "\n",
    "# Mache eine Vorhersage (ohne Gradientenberechnung für mehr Geschwindigkeit)\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "\n",
    "# Konvertiere die Ausgabe in Wahrscheinlichkeiten und finde die Top 3\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "top3_prob, top3_catid = torch.topk(probabilities, 3)\n",
    "\n",
    "print(\"Top 3 Vorhersagen des Modells:\")\n",
    "for i in range(top3_prob.size(0)):\n",
    "    label = idx2label[top3_catid[i]]\n",
    "    score = top3_prob[i].item()\n",
    "    print(f\"{i+1}: {label} ({score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setze 'requires_grad' für unseren Input-Tensor, damit wir den Gradienten berechnen können\n",
    "img_tensor.requires_grad_()\n",
    "\n",
    "# Führe das Bild nochmal durchs Modell (diesmal mit Gradientenberechnung)\n",
    "output = model(img_tensor)\n",
    "output_max = output.max() # Wir interessieren uns für den Gradienten der stärksten Aktivierung\n",
    "\n",
    "# Berechne den Gradienten\n",
    "output_max.backward()\n",
    "\n",
    "# Hole den Gradienten und verarbeite ihn für die Visualisierung\n",
    "saliency, _ = torch.max(img_tensor.grad.data.abs(), dim=1)\n",
    "saliency = saliency.squeeze(0) # Entferne die Batch-Dimension\n",
    "\n",
    "# Visualisierung\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# Wir müssen die Transformationen für die Anzeige rückgängig machen\n",
    "unnormalized_img = img_tensor.squeeze(0).detach().numpy().transpose(1, 2, 0)\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "unnormalized_img = std * unnormalized_img + mean\n",
    "unnormalized_img = np.clip(unnormalized_img, 0, 1)\n",
    "\n",
    "axs[0].imshow(unnormalized_img)\n",
    "axs[0].set_title('Originalbild')\n",
    "axs[0].axis('off')\n",
    "\n",
    "im = axs[1].imshow(saliency, cmap='hot')\n",
    "axs[1].set_title('Saliency Map (PyTorch)')\n",
    "axs[1].axis('off')\n",
    "fig.colorbar(im, ax=axs[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
